---
layout: page
permalink: /cfp/
title: Call for Papers
description:
nav: true
nav_order: 1
---

We invite submissions for the ICML 2024 workshop <em>Aligning Reinforcement Learning Experimentalists and Theorists</em>. The papers can present new work or summarize the recent work of the author(s). Papers submitted or accepted to other conferences or journals are also welcome. Submitted papers will be reviewed by the program committee. All accepted papers will have a poster presentation. Outstanding papers will also be considered for contributed talks of approximately 15 minutes each. Please note that at least one author of each accepted paper must be available for the poster and/or oral presentation. There will be no proceedings.

<h2>Important dates</h2>

- Submission deadline: ``May 29th, 2024, AoE``.
- Reviewer registration link: ``TBD``.
- Submission link: ``TBD``.
- Notification of acceptance: ``June 17th, 2024, AoE``.
- Posters and camera ready: ``July 21st, 2024, AoE``.


<h2>Submission instructions</h2>

The page limit is 8 pages (excluding references and the appendix). Submissions may include supplementary material, but reviewers are only required to read the first 8 pages. Submissions should use the template provided by the [NeurIPS 2024 LaTeX style file](/assets/files/neurips2024_styles.zip). The reviewing process is blind. Parallel submissions (to a journal, conference, workshop, or preprint repository) are allowed. Authors planning to submit already accepted articles are allowed to submit the full article but are asked to make it clear that the work already went through a peer-review process.

<h2>Goal of the workshop</h2>

Reinforcement learning has evolved into a dynamic and expansive field, attracting both theorists and experimentalists. While theorists and experimentalists in reinforcement learning share a common interest in advancing the field, their research objectives, methodologies, and challenges sometimes diverge significantly. This workshop aims to bridge this gap by bringing them closer together and to shed light on recent developments and synergies in both communities.

<h2>Topics</h2>

The workshop will cover a range of sub-topics including (but not limited to):
- MDPs and Dynamic Programming
- Temporal Difference Methods
- Policy Optimization
- Model-based RL and Planning
- Exploration in RL
- Offline RL
- Unsupervised and Intrinsically Motivated RL
- Representation Learning in RL
- Lifelong and Non-stationary RL
- Hierarchical RL
- Partially Observable RL
- Multi-Agent RL
- Multi-Objective RL
- Transfer and Meta RL
- Deep RL
- Imitation Learning and Inverse RL
- Risk-sensitive and Robust RL
- Real-world applications of RL
